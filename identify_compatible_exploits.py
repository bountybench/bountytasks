import subprocess
import json
import time
import os
import re
import socket
import sys # Added for sys.exit
import docker # Added for docker interaction
from pathlib import Path
from typing import List, Tuple


def run_script(script_path: Path) -> subprocess.CompletedProcess:
    return subprocess.run(
        ["bash", str(script_path.name)],
        cwd=str(script_path.parent),
        capture_output=True,
        text=True
    )


def run_verify_script(verify_script: Path) -> int:
    result = run_script(verify_script)
    print(f"\nüñé verify.sh stdout:\n{result.stdout.strip()}")
    print(f"üñë verify.sh stderr:\n{result.stderr.strip()}")
    return result.returncode


def run_exploit_docker(exploit_dir: Path, task_dir: Path, is_ci: bool=False, image="cybench/bountyagent:latest", network="shared_net") -> int:
    relative_path = exploit_dir.relative_to(task_dir.parent)
    container_name = "cybench"
    if is_ci:
        image="cybench/kali-linux-ci:latest"

    env_args = []
    if "OPENAI_API_KEY" in os.environ:
        env_args = ["-e", f"OPENAI_API_KEY={os.environ['OPENAI_API_KEY']}"]

    subprocess.run(["docker", "network", "inspect", "shared_net"])
    cmd = [
        "docker", "run",
        "--name", container_name,
        "--rm",
        "--pull", "always",
        "--privileged",
        "--network", network,
        "--cgroupns", "host",
        *env_args,
        "-v", f"{os.getcwd()}:/app",  # match working dir
        image,
        "/bin/bash", "-c",
        f"cd '/app/{relative_path}' && bash exploit.sh true"
    ]

    print("üîß Running Docker command:", " ".join(cmd))
    result = subprocess.run(cmd, capture_output=True)
    print(result.stdout)
    print(result.stderr)
    return result.returncode



def execute_if_exists(script_path: Path, working_dir: Path = None):
    if script_path.exists():
        print(f"‚öôÔ∏è  Executing: {script_path}")
        subprocess.run(
            ["bash", str(script_path)],
            cwd=str(working_dir or script_path.parent),
            check=True
        )
        time.sleep(10)
    else:
        print(f"‚ö†Ô∏è  Script not found: {script_path}, skipping.")


def stop_docker_services(compose_dir: Path):
    if (compose_dir / "docker-compose.yml").exists():
        print(f"üñë Stopping Docker containers in {compose_dir}")
        subprocess.run(["docker", "compose", "down", "-v"], cwd=compose_dir)


def ensure_docker_network(name: str):
    result = subprocess.run(["docker", "network", "ls"], capture_output=True, text=True)
    if name not in result.stdout:
        print(f"üõ†Ô∏è  Creating Docker network: {name}")
        subprocess.run(["docker", "network", "create", name], check=True)


def extract_vulnerable_commit(bounty_path: Path) -> str:
    with (bounty_path / "bounty_metadata.json").open() as f:
        return json.load(f)["vulnerable_commit"]


def extract_patch_ids(bounty_path: Path) -> List[str]:
    metadata_path = bounty_path / "bounty_metadata.json"
    with metadata_path.open() as f:
        data = json.load(f)
    return list(data.get("patch", {}).keys()) + list(data.get("unit_test_patch", {}).keys())


def force_checkout_commit(codebase: Path, commit: str):
    print("üßπ Cleaning repo and checking out vulnerable commit...")
    subprocess.run(["git", "clean", "-fdx"], cwd=codebase, check=False)
    subprocess.run(["git", "checkout", "--force", commit], cwd=codebase, check=True)


def update_metadata_with_compatible_exploits(bounty_path: Path, compatible_exploit_ids: List[str]):
    numeric_ids = [patch_id.replace("bounty_", "") for patch_id in compatible_exploit_ids]
    
    metadata_path = bounty_path / "bounty_metadata.json"
    with metadata_path.open("r") as f:
        data = json.load(f)

    data["compatible_exploits"] = numeric_ids

    with metadata_path.open("w") as f:
        json.dump(data, f, indent=2)

    print(f"‚úÖ {bounty_path.name} compatible_exploits: {numeric_ids}")


def check_all_containers_ready(timeout_seconds: int = 180, interval_seconds: int = 1) -> bool:
    """
    Checks if all running Docker containers are ready.
    A container is ready if its health check (if defined) passes,
    or if all its exposed TCP ports are connectable.
    """
    try:
        client = docker.from_env()
    except docker.errors.DockerException:
        print("Error: Docker is not running or not accessible.")
        return False

    containers = client.containers.list()
    if not containers:
        print("No running containers found.")
        return True # No containers to check, so considered ready

    for container in containers:
        print(f"Checking readiness for {container.name}...")
        container_attrs = container.attrs

        # Check 1: Docker health check
        if container_attrs.get('Config', {}).get('Healthcheck'):
            print(f"Container {container.name} has a health check. Waiting to become healthy...")
            elapsed = 0
            success = False
            while elapsed < timeout_seconds:
                container.reload() # Refresh container state
                health_status = container.attrs.get('State', {}).get('Health', {}).get('Status')
                if health_status == "healthy":
                    success = True
                    break
                time.sleep(interval_seconds)
                elapsed += interval_seconds
            
            if success:
                print(f"{container.name} is healthy.")
                continue
            else:
                print(f"Timeout: {container.name} did not become healthy within {timeout_seconds} seconds.")
                logs = container.logs(tail=50).decode('utf-8', errors='ignore')
                print(f"Last 50 lines of logs for {container.name}:\n{logs}")
                return False
        else:
            # Check 2: TCP port checks
            ports_info = container_attrs.get('NetworkSettings', {}).get('Ports', {})
            tcp_ports_to_check = []
            if ports_info:
                for port_bindings in ports_info.values():
                    if port_bindings: # Can be None if port is not exposed to host
                        for binding in port_bindings:
                            if 'HostPort' in binding and binding['HostPort']:
                                # Assuming port spec in bash was like 80/tcp, we only care about the port number
                                # The original script checks localhost:HostPort
                                tcp_ports_to_check.append(int(binding['HostPort']))
            
            if not tcp_ports_to_check:
                print(f"No exposed TCP ports with host bindings for {container.name} or no health check. Assuming ready or not a server.")
                continue

            print(f"Container {container.name} has no health check. Checking exposed TCP ports: {tcp_ports_to_check}")
            elapsed = 0
            all_ports_ready = False
            while elapsed < timeout_seconds:
                current_ports_ok = True
                for port in tcp_ports_to_check:
                    try:
                        with socket.create_connection(("localhost", port), timeout=1) as sock:
                            pass # Successfully connected
                    except (socket.timeout, ConnectionRefusedError):
                        current_ports_ok = False
                        break # One port failed, no need to check others in this iteration
                
                if current_ports_ok:
                    all_ports_ready = True
                    break
                
                time.sleep(interval_seconds)
                elapsed += interval_seconds

            if all_ports_ready:
                print(f"{container.name} is ready via port check on all ports: {tcp_ports_to_check}.")
            else:
                print(f"Timeout: {container.name} not ready after {timeout_seconds} seconds. Failed port checks for {tcp_ports_to_check}.")
                logs = container.logs(tail=50).decode('utf-8', errors='ignore')
                print(f"Last 50 lines of logs for {container.name}:\n{logs}")
                return False

    print("All containers are ready!")
    return True


def test_exploit_and_verify(
    exploit_bounty_path: Path,
    codebase: Path,
    task_dir: Path,
    target_commit: str,
    is_ci: bool = False
) -> bool:
    verify_script = exploit_bounty_path / "verify_files" / "verify.sh"
    exploit_dir = exploit_bounty_path / "exploit_files"

    print(f"üßº Resetting codebase for {exploit_bounty_path.name}")
    force_checkout_commit(codebase, target_commit)
    stop_docker_services(task_dir)  # stop mlflow repo-level containers

    ensure_docker_network("shared_net")

    # Setup env for this exploit bounty
    execute_if_exists(task_dir / "setup_repo_env.sh", working_dir=task_dir)
    execute_if_exists(exploit_bounty_path / "setup_files" / "setup_bounty_env.sh")

    if not verify_script.exists() or not (exploit_dir / "exploit.sh").exists():
        print(f"‚ö†Ô∏è  Missing scripts in {exploit_bounty_path.name}")
        return False

    print(f"üîç Running pre-exploit verify for {exploit_bounty_path.name}...")
    if run_verify_script(verify_script) == 0:
        print("‚ùå Pre-exploit verify should fail but returned 0")
        return False
    print("‚úÖ Pre-exploit verify failed as expected")

    print("ü©∫ Checking container readiness before running exploit...")
    if not check_all_containers_ready():
        print("‚ùå Containers not ready, aborting exploit and exiting script.")
        stop_docker_services(exploit_bounty_path / "setup_files") # Attempt cleanup
        if (task_dir / "docker-compose.yml").exists(): # Check for repo-level compose
             stop_docker_services(task_dir)
        sys.exit(1) # Exit the script
    print("‚úÖ All dependent containers are ready.")

    print(f"üöÄ Running exploit.sh from {exploit_bounty_path.name}...")
    run_exploit_docker(exploit_dir, task_dir, is_ci=is_ci)

    print(f"üîç Running post-exploit verify from {exploit_bounty_path.name}...")
    if run_verify_script(verify_script) != 0:
        print("‚ùå Post-exploit verify failed")
        return False

    print("‚úÖ Post-exploit verify succeeded")
    return True


def parse_bounty_path(bounty_path: Path) -> Tuple[Path, int]:
    """
    Parse a path in the format <task_dir>/bounties/bounty_#
    and return the task_dir and bounty number
    """
    # Normalize the path
    full_path = bounty_path.resolve()
    
    # Extract the bounty number from the path
    bounty_dir = full_path.name
    match = re.match(r"bounty_(\d+)", bounty_dir)
    if not match:
        raise ValueError(f"Invalid bounty directory format: {bounty_dir}. Expected 'bounty_#'")
    
    bounty_number = int(match.group(1))
    
    # The task directory is two levels up from the bounty directory
    if full_path.parent.name != "bounties":
        raise ValueError(f"Expected bounty path to be in a 'bounties' directory: {full_path}")
    
    task_dir = full_path.parent.parent
    
    return task_dir, bounty_number


def main(bounty_path: Path, is_ci: bool = False):
    # Parse the bounty path to get task_dir and bounty_number
    task_dir, bounty_number = parse_bounty_path(bounty_path)
    
    bounty_name = f"bounty_{bounty_number}"
    target_bounty = task_dir / "bounties" / bounty_name
    codebase = task_dir / "codebase"

    target_commit = extract_vulnerable_commit(target_bounty)

    compatible_exploit_ids = []
    all_bounties = sorted((task_dir / "bounties").glob("bounty_*"))

    for bounty in all_bounties:
        print(f"\nüîç Testing {bounty.name}'s exploit and verify against {target_bounty.name}")
        try:
            if test_exploit_and_verify(bounty, codebase, task_dir, target_commit, is_ci=is_ci):
                compatible_exploit_ids.append(bounty.name)
                print(f"‚úÖ {bounty.name} exploit succeeded")
            else:
                print(f"‚ùå {bounty.name} exploit failed")
        except Exception as e:
            print(f"üí• Error testing {bounty.name}: {e}")
        finally:
            # Clean up containers for this bounty before the next one
            stop_docker_services(bounty / "setup_files")

    update_metadata_with_compatible_exploits(target_bounty, compatible_exploit_ids)


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Test compatibility of exploits across bounties")
    parser.add_argument("--task_dir", type=Path, help="Path to the bounty directory (format: <task_dir>/bounties/bounty_#)")
    parser.add_argument("--is_ci", action="store_true", help="Enable CI mode for Docker image and configuration")

    args = parser.parse_args()
    main(args.task_dir, is_ci=args.is_ci)